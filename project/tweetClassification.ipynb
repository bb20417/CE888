{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweetClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWq7XMiHR3+M1UFe2CXJWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bb20417/CE888/blob/main/project/tweetClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgCsTBI_3Yx5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "!pip install chart_studio\n",
        "!pip install textstat\n",
        "\n",
        "# Visualisation libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "import chart_studio.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.offline import iplot\n",
        "import cufflinks\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOl5MeN-t_Ts"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPhrtQdECH4W"
      },
      "source": [
        "My chosen datasets are: **Offensive language identification, Sentiment analysis and Emotion rec**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCYty4a83bAs"
      },
      "source": [
        "## Loading all the datasets.\n",
        "\n",
        "Total 21 datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfjXPCshbaWi"
      },
      "source": [
        "#load emotion data\n",
        "#traindf=pd.read_csv('../input/semeval-2018-task-ec/2018-E-c-En-train.txt',encoding='utf-8',sep=\"\\t\")\n",
        "emo_train_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/train_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_train_text.columns= [\"tweet_text\"]\n",
        "emo_train_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/train_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_train_label.columns= [\"tweet_label\"]\n",
        "\n",
        "\n",
        "emo_val_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/val_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_val_text.columns= [\"tweet_text\"]\n",
        "emo_val_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/val_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_val_label.columns= [\"tweet_label\"]\n",
        "\n",
        "emo_test_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/test_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_test_text.columns= [\"tweet_text\"]\n",
        "emo_test_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/test_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_test_label.columns= [\"tweet_label\"]\n",
        "\n",
        "emo_map = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/mapping.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "emo_map.columns= [\"tweet_label\",\"emotion\"]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON7aAPiGoA_y",
        "outputId": "13b760ac-90f3-43e8-ff66-5f2351cac884"
      },
      "source": [
        "emo_train_label.shape, emo_train_text.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3257, 1), (3257, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG4xwHGPVm69"
      },
      "source": [
        "#loading Sentiment data\n",
        "sent_train_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_train_text.columns= [\"tweet_text\"]\n",
        "sent_train_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_train_label.columns= [\"tweet_label\"]\n",
        "\n",
        "\n",
        "sent_val_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/val_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_val_text.columns= [\"tweet_text\"]\n",
        "sent_val_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/val_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_val_label.columns= [\"tweet_label\"]\n",
        "\n",
        "sent_test_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_test_text.columns= [\"tweet_text\"]\n",
        "sent_test_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_test_label.columns= [\"tweet_label\"]\n",
        "\n",
        "\n",
        "sent_map = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "sent_map.columns= [\"tweet_label\",\"sentiment\"]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FPgj_hm6ui4",
        "outputId": "4a6807a7-6ebd-4c6f-f7a8-47d22a702a6b"
      },
      "source": [
        "sent_train_text.isna().sum()  \n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Tzd6VI_S1O",
        "outputId": "457825e9-5ddc-47c7-de77-b3bc23f9cd5a"
      },
      "source": [
        "sent_train_text.shape, sent_train_label.shape\n",
        "sent_val_text.shape, sent_val_label.shape\n",
        "sent_test_text.shape, sent_test_label.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((36373, 1), (45615, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1623, 1), (2000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12032, 1), (12284, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dhQs_tS_SXg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_n-PWtnH9uT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twUdZI1JFKHg"
      },
      "source": [
        "#loading offensive data\n",
        "off_train_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_train_text.columns= [\"tweet_text\"]\n",
        "off_train_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/train_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_train_label.columns= [\"tweet_label\"]\n",
        "\n",
        "\n",
        "off_val_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_val_text.columns= [\"tweet_text\"]\n",
        "off_val_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/val_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_val_label.columns= [\"tweet_label\"]\n",
        "\n",
        "off_test_text = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_text.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_test_text.columns= [\"tweet_text\"]\n",
        "off_test_label = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/test_labels.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_test_label.columns= [\"tweet_label\"]\n",
        "\n",
        "\n",
        "off_map = pd.read_csv(\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/mapping.txt\",encoding='utf-8',sep=\"\\t\", header=None)\n",
        "off_map.columns= [\"tweet_label\",\"offensive\"]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dSc8MkbDBmd",
        "outputId": "dc997235-08de-4030-cdff-0ae1ae13fc33"
      },
      "source": [
        "off_train_text.shape, off_train_label.shape\n",
        "off_val_text.shape, off_val_label.shape\n",
        "off_test_text.shape, off_test_label.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11916, 1), (11916, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1324, 1), (1324, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((860, 1), (860, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWMtLJ533CHq"
      },
      "source": [
        "# **Emotion** dataset inital EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM5IBrxuniN0"
      },
      "source": [
        "#concatenating dataframe to make one dataset each for train, validation and test df\n",
        "df_emo_train = pd.concat([emo_train_text,emo_train_label], axis=1)\n",
        "df_emo_val = pd.concat([emo_val_text,emo_val_label], axis=1)\n",
        "df_emo_test = pd.concat([emo_test_text,emo_test_label], axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HgpVrTzpHhD"
      },
      "source": [
        "combo_train = pd.merge(df_emo_train,emo_map, on='tweet_label')\n",
        "combo_val = pd.merge(df_emo_val,emo_map, on='tweet_label')\n",
        "combo_test = pd.merge(df_emo_test,emo_map, on='tweet_label')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gSC9gt9p3xa"
      },
      "source": [
        "g = (sns.catplot(x=\"emotion\", kind=\"count\", palette=\"ch:.25\", data=combo_train))\n",
        "g.fig.suptitle(\"Training set\", y=1.03)\n",
        "plt.show()\n",
        "\n",
        "v = sns.catplot(x=\"emotion\", kind=\"count\", palette=\"ch:.25\", data=combo_val)\n",
        "v.fig.suptitle(\"Validation set\", y=1.03)\n",
        "plt.show()\n",
        "\n",
        "t = sns.catplot(x=\"emotion\", kind=\"count\", palette=\"ch:.25\", data=combo_test)\n",
        "t.fig.suptitle(\"Test set\", y=1.03)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spUamxQe06Hu"
      },
      "source": [
        "all the three datasets are similarly unbalanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAopzrYR3o5L"
      },
      "source": [
        "# **Sentiment** dataset inital EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG8wO-bap_Pw"
      },
      "source": [
        "#concatenating dataframe to make one dataset each for train, validation and test df\n",
        "df_sent_train = pd.concat([sent_train_text,sent_train_label], axis=1)\n",
        "df_sent_val = pd.concat([sent_val_text,sent_val_label], axis=1)\n",
        "df_sent_test = pd.concat([sent_test_text,sent_test_label], axis=1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHHpmoHowSyE"
      },
      "source": [
        "sent_combo_train = pd.merge(df_sent_train,sent_map, on='tweet_label')\n",
        "sent_combo_val = pd.merge(df_sent_val,sent_map, on='tweet_label')\n",
        "sent_combo_test = pd.merge(df_sent_test,sent_map, on='tweet_label')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9wgs4Guy734"
      },
      "source": [
        "g = (sns.catplot(x=\"sentiment\", kind=\"count\", palette=\"ch:.25\", data=sent_combo_train))\n",
        "g.fig.suptitle(\"Training set\", y=1.03)\n",
        "plt.show()\n",
        "\n",
        "v = sns.catplot(x=\"sentiment\", kind=\"count\", palette=\"ch:.25\", data=sent_combo_val)\n",
        "v.fig.suptitle(\"Validation set\", y=1.03)\n",
        "plt.show()\n",
        "\n",
        "t = sns.catplot(x=\"sentiment\", kind=\"count\", palette=\"ch:.25\", data=sent_combo_test)\n",
        "t.fig.suptitle(\"Test set\", y=1.03)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4nKMr29X6YIu",
        "outputId": "1166b9b7-5578-426a-8259-6afe5d732ef5"
      },
      "source": [
        "sent_combo_train.tail()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>tweet_label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45610</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45611</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45612</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45613</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45614</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tweet_text  tweet_label sentiment\n",
              "45610        NaN            0  negative\n",
              "45611        NaN            0  negative\n",
              "45612        NaN            0  negative\n",
              "45613        NaN            0  negative\n",
              "45614        NaN            0  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRe0N4cb5OX_"
      },
      "source": [
        "All the three datasets are unbalanced. Therefore accuracy cannot be a suitable evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nUzu0N55eOD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR2ltvsl5gtx"
      },
      "source": [
        "# **Offensive** dataset inital EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0mgl8nu5gt7"
      },
      "source": [
        "#concatenating dataframe to make one dataset each for train, validation and test df\n",
        "df_off_train = pd.concat([off_train_text,off_train_label], axis=1)\n",
        "df_off_val = pd.concat([off_val_text,off_val_label], axis=1)\n",
        "df_off_test = pd.concat([off_test_text,off_test_label], axis=1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNvyzDH55gt7"
      },
      "source": [
        "off_combo_train = pd.merge(df_off_train,off_map, on='tweet_label')\n",
        "off_combo_val = pd.merge(df_off_val,off_map, on='tweet_label')\n",
        "off_combo_test = pd.merge(df_off_test,off_map, on='tweet_label')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tghK0UtA5gt8"
      },
      "source": [
        "g = (sns.catplot(x=\"offensive\", kind=\"count\", palette=\"ch:.25\", data=off_combo_train))\n",
        "g.fig.suptitle(\"Training set\", y=1.03)\n",
        "plt.show()\n",
        "\n",
        "v = sns.catplot(x=\"offensive\", kind=\"count\", palette=\"ch:.25\", data=off_combo_val)\n",
        "v.fig.suptitle(\"Validation set\", y=1.03)\n",
        "plt.show()\n",
        "\n",
        "t = sns.catplot(x=\"offensive\", kind=\"count\", palette=\"ch:.25\", data=off_combo_test)\n",
        "t.fig.suptitle(\"Test set\", y=1.03)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oLq6u_Y6R74",
        "outputId": "e4f8e849-dc4f-4a12-8702-0bcc269ca462"
      },
      "source": [
        "off_combo_train.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11916, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcyQq04Y2tY7"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv-H6ItIgGwj"
      },
      "source": [
        "#  sum=0\n",
        "#  for t in train_text['tweet_text']:\n",
        "#    for s in t.split():\n",
        "#      sum+= (s.isupper())\n",
        "\n",
        "# print(sum)\n",
        "# #print(sum(sum))\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}